{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers[torch] datasets[audio] audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "esc50 = load_dataset(\"ashraq/esc50\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VITS\n",
    "\n",
    "VITS by NeMo is an implementation of the Variational Inference Text-to-Speech (VITS) model within NVIDIA's NeMo framework providing a user-friendly interface for researchers and developers. NeMo's VITS implementation is designed to facilitate easy training, fine-tuning, and deployment of high-quality TTS systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-09-23 03:00:40 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:253: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "      @custom_fwd\n",
      "    \n",
      "[NeMo W 2024-09-23 03:00:40 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:264: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "      @custom_bwd\n",
      "    \n",
      "[NeMo W 2024-09-23 03:00:40 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:324: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "      @custom_fwd\n",
      "    \n",
      "[NeMo W 2024-09-23 03:00:40 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "      @custom_bwd\n",
      "    \n",
      "[NeMo W 2024-09-23 03:00:43 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/nemo/collections/tts/modules/common.py:206: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      @amp.autocast(False)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PretrainedModelInfo(\n",
      "\tpretrained_model_name=tts_en_lj_vits,\n",
      "\tdescription=This model is trained on LJSpeech audio sampled at 22050Hz. This model has been tested on generating female English voices with an American accent.,\n",
      "\tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_vits/versions/1.13.0/files/vits_ljspeech_fp16_full.nemo,\n",
      "\tclass_=<class 'nemo.collections.tts.models.vits.VitsModel'>\n",
      "), PretrainedModelInfo(\n",
      "\tpretrained_model_name=tts_en_hifitts_vits,\n",
      "\tdescription=This model is trained on HiFITTS sampled at 44100Hz with and can be used to generate male and female English voices with an American accent.,\n",
      "\tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_hifitts_vits/versions/r1.15.0/files/vits_en_hifitts.nemo,\n",
      "\tclass_=<class 'nemo.collections.tts.models.vits.VitsModel'>\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Load the VITSModel\n",
    "from nemo.collections.tts.models import VitsModel\n",
    "from nemo.collections.tts.models.base import TextToWaveform\n",
    "\n",
    "# Let's see what pretrained models are available\n",
    "print(VitsModel.list_available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-09-23 03:03:14 nemo_logging:381] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_vits/versions/1.13.0/files/vits_ljspeech_fp16_full.nemo to /home/levi/.cache/torch/NeMo/NeMo_1.23.0/vits_ljspeech_fp16_full/aafc8db3ad2124ec6f77d4d20f3fddaf/vits_ljspeech_fp16_full.nemo\n",
      "[NeMo I 2024-09-23 03:03:33 nemo_logging:381] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2024-09-23 03:03:52 nemo_logging:393] Function ``g2p_backward_compatible_support`` is deprecated. But it will not be removed until a further notice. G2P object root directory `nemo_text_processing.g2p` has been replaced with `nemo.collections.tts.g2p`. Please use the latter instead as of NeMo 1.18.0.\n",
      "[NeMo W 2024-09-23 03:03:52 nemo_logging:393] `<class 'nemo.collections.tts.g2p.models.i18n_ipa.IpaG2p'>` is experimental and not ready for production yet. Use at your own risk.\n",
      "[NeMo W 2024-09-23 03:03:53 nemo_logging:393] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2024-09-23 03:03:53 nemo_logging:393] `<class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'>` is experimental and not ready for production yet. Use at your own risk.\n",
      "[NeMo W 2024-09-23 03:03:53 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /raid/datasets/tts_data/train_manifest.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: null\n",
      "      sup_data_types: null\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: null\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "    dataloader_params:\n",
      "      num_workers: 8\n",
      "      pin_memory: false\n",
      "    batch_sampler:\n",
      "      batch_size: 32\n",
      "      boundaries:\n",
      "      - 32\n",
      "      - 300\n",
      "      - 400\n",
      "      - 500\n",
      "      - 600\n",
      "      - 700\n",
      "      - 800\n",
      "      - 900\n",
      "      - 1000\n",
      "      num_replicas: 8\n",
      "      shuffle: true\n",
      "    \n",
      "[NeMo W 2024-09-23 03:03:53 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /raid/datasets/tts_data/val_manifest.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: null\n",
      "      sup_data_types: null\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: null\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 16\n",
      "      num_workers: 4\n",
      "      pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-09-23 03:03:53 nemo_logging:381] PADDING: 1\n",
      "[NeMo I 2024-09-23 03:03:53 nemo_logging:381] STFT using exact pad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-09-23 03:03:53 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "      WeightNorm.apply(module, name, dim)\n",
      "    \n",
      "[NeMo W 2024-09-23 03:03:54 nemo_logging:393] /home/levi/Speech-Course-Lab/env/lib/python3.11/site-packages/nemo/core/connectors/save_restore_connector.py:571: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "      return torch.load(model_weights, map_location='cpu')\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-09-23 03:03:54 nemo_logging:381] Model VitsModel was successfully restored from /home/levi/.cache/torch/NeMo/NeMo_1.23.0/vits_ljspeech_fp16_full/aafc8db3ad2124ec6f77d4d20f3fddaf/vits_ljspeech_fp16_full.nemo.\n"
     ]
    }
   ],
   "source": [
    "# We can load the pre-trained model as follows\n",
    "model = VitsModel.from_pretrained(\"tts_en_lj_vits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-23 03:06:07--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/vits.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1216 (1.2K) [text/plain]\n",
      "Saving to: ‘vits.py’\n",
      "\n",
      "vits.py             100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-23 03:06:08 (192 MB/s) - ‘vits.py’ saved [1216/1216]\n",
      "\n",
      "--2024-09-23 03:06:08--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/conf/vits.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5599 (5.5K) [text/plain]\n",
      "Saving to: ‘vits.yaml’\n",
      "\n",
      "vits.yaml           100%[===================>]   5.47K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-23 03:06:08 (136 MB/s) - ‘vits.yaml’ saved [5599/5599]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NeMo's training scripts are stored inside the examples/ folder. Let's grab the vits.py file\n",
    "# as well as the vits.yaml file\n",
    "# download ./conf\n",
    "BRANCH = 'main'\n",
    "!wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/tts/vits.py\n",
    "!(mkdir -p conf \\\n",
    "  && cd conf \\\n",
    "  && wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/tts/conf/vits.yaml \\\n",
    "  && cd ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-23 03:06:18--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tts_dataset_files/ipa_cmudict-0.7b_nv23.01.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3093097 (2.9M) [text/plain]\n",
      "Saving to: ‘ipa_cmudict-0.7b_nv23.01.txt’\n",
      "\n",
      "ipa_cmudict-0.7b_nv 100%[===================>]   2.95M  7.39MB/s    in 0.4s    \n",
      "\n",
      "2024-09-23 03:06:19 (7.39 MB/s) - ‘ipa_cmudict-0.7b_nv23.01.txt’ saved [3093097/3093097]\n",
      "\n",
      "--2024-09-23 03:06:19--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tts_dataset_files/heteronyms-052722\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1606 (1.6K) [text/plain]\n",
      "Saving to: ‘heteronyms-052722’\n",
      "\n",
      "heteronyms-052722   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-23 03:06:20 (13.9 MB/s) - ‘heteronyms-052722’ saved [1606/1606]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# additional files\n",
    "BRANCH = 'main'\n",
    "!mkdir -p tts_dataset_files && cd tts_dataset_files \\\n",
    "&& wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/ipa_cmudict-0.7b_nv23.01.txt \\\n",
    "&& wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/heteronyms-052722 \\\n",
    "&& cd ..\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(python vits.py \\\n",
    "  model.sample_rate=22050 \\\n",
    "  train_dataset=tests/data/asr/an4_train.json \\\n",
    "  validation_datasets=tests/data/asr/an4_val.json \\\n",
    "  phoneme_dict_path=tts_dataset_files/ipa_cmudict-0.7b_nv23.01.txt \\\n",
    "  heteronyms_path=tts_dataset_files/heteronyms-052722 \\\n",
    "  trainer.max_epochs=3 \\\n",
    "  trainer.accelerator='gpu' \\\n",
    "  trainer.strategy='ddp_find_unused_parameters_true' \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    "  trainer.devices=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
