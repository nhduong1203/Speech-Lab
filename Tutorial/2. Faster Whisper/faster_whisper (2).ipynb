{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhkv19W6QBXg"
      },
      "source": [
        "# Introduction to Faster Whisper \n",
        "\n",
        "## Whisper: Robust Speech Recognition via Large-Scale Weak Supervision\n",
        "\n",
        "Whisper, developed by OpenAI, excels in Automatic Speech Recognition (ASR) tasks by demonstrating high performance and strong generalization across datasets and domains without requiring fine-tuning. Its strength lies in training on an extensive dataset of 680,000 hours of multilingual and multitask supervised data sourced from the web. This dataset includes audio paired with existing transcriptions, such as videos with transcriptions provided by owners on platforms like YouTube. This approach minimizes the effort spent on labeling data and instead focuses on data cleaning, hence termed \"Weak Supervision.\"\n",
        "\n",
        "At the core of Whisper is a Transformer-based sequence-to-sequence model trained across various speech processing tasks: multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. This diversity makes Whisper a robust ASR model.\n",
        "\n",
        "## CTranslate2 and Faster-Whisper: Optimizing Transformer Model Inference\n",
        "\n",
        "CTranslate2 is a C++ and Python library designed for efficient inference with Transformer models. Engineered for high performance, it incorporates optimizations such as weight quantization, layer fusion, and batch reordering. These optimizations enhance speed and minimize memory usage on both CPUs and GPUs.\n",
        "\n",
        "CTranslate2 supports a diverse array of model types, catering to various needs:\n",
        "\n",
        "- **Encoder-decoder** models like Transformer base/big, M2M-100, and Whisper.\n",
        "- **Decoder-only** models such as GPT-2, GPT-J, and BERT.\n",
        "- **Encoder-only** models like BERT and XLM-RoBERTa.\n",
        "\n",
        "Faster-Whisper utilizes the Whisper model implemented with CTranslate, offering up to 4 times faster inference speeds with reduced memory usage compared to openai/whisper, while maintaining the same accuracy. Further efficiency gains are achievable through 8-bit quantization on both CPU and GPU.\n",
        "\n",
        "## What's make it fast?\n",
        "\n",
        "- Optimized Execution: The framework achieves fast and efficient execution on both CPU and GPU through a variety of advanced optimizations. These include layer fusion, padding removal, batch reordering, in-place operations, and caching mechanisms, resulting in reduced resource consumption compared to general-purpose deep learning frameworks.\n",
        "\n",
        "- Quantization and Precision Reduction: The framework supports model serialization and computation with weights of reduced precision, including 16-bit floating-point (FP16), 16-bit brain floating-point (BF16), 16-bit integer (INT16), 8-bit integer (INT8), and AWQ quantization (INT4). These techniques contribute to improved performance and reduced model size.\n",
        "\n",
        "## Benchmark\n",
        "\n",
        "For reference, here's the time and memory usage that are required to transcribe 13 minutes of audio using different implementations.\n",
        "\n",
        "- Large-v2 model on GPU\n",
        "\n",
        "- Small model on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a11uqi6TSvmm"
      },
      "source": [
        "3. \n",
        "- Support for Multiple CPU Architectures: The system is compatible with x86-64 and AArch64/ARM64 processors, incorporating multiple optimized backends such as Intel MKL, oneDNN, OpenBLAS, Ruy, and Apple Accelerate. This ensures broad compatibility and efficient execution across different platforms.\n",
        "\n",
        "- Automatic CPU Detection and Code Dispatch: The binary is designed to include multiple backends (e.g., Intel MKL and oneDNN) and instruction set architectures (e.g., AVX, AVX2). The appropriate backend and instruction set are automatically selected at runtime based on the detected CPU configuration.\n",
        "\n",
        "- Parallel and Asynchronous Execution: The framework supports parallel and asynchronous processing of multiple batches using multiple GPUs or CPU cores, enabling efficient handling of large-scale computations.\n",
        "\n",
        "- Dynamic Memory Management: Memory usage is dynamically adjusted according to request size, facilitated by caching allocators for both CPU and GPU. This approach ensures that performance requirements are met while optimizing memory utilization.\n",
        "\n",
        "- Reduced Disk Footprint: Quantization techniques can reduce model sizes on disk by up to four times with minimal loss in accuracy, contributing to more efficient storage and deployment.\n",
        "\n",
        "- Simple Integration: The project features minimal dependencies and provides straightforward APIs in Python and C++ for ease of integration, covering a broad range of integration scenarios.\n",
        "\n",
        "- Configurable and Interactive Decoding: The framework offers advanced decoding capabilities, including the ability to autocomplete partial sequences and return alternative outputs at specific points in the sequence, enhancing flexibility and accuracy in inference.\n",
        "\n",
        "- Tensor Parallelism for Distributed Inference: For very large models, the framework supports tensor parallelism, allowing models to be distributed across multiple GPUs. The documentation provides detailed instructions for setting up the necessary environment for distributed inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxf49wJjb09S"
      },
      "source": [
        "# CTranslate2 Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWB7DZDhfsJY"
      },
      "source": [
        "CTranslate2 is designed specifically for efficient inference of transformer-based models, which are widely used for various natural language processing (NLP) and machine translation tasks. The primary tasks it implements include:\n",
        "- Text translation\n",
        "- Text generation\n",
        "- Text encoding\n",
        "- Speech recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1FHYrGCIt2w"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "To install Ctranslate Whisper, run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zy_WExF6b53s",
        "outputId": "dc3747f3-b975-4e64-b811-9196da65741a"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install transformers[torch]>=4.23\n",
        "!pip install --upgrade ctranslate2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GibdJNlO6ZbU"
      },
      "source": [
        "## Import libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "Ut77zwrlf7id"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torchaudio\n",
        "from transformers import WhisperTokenizer, WhisperProcessor\n",
        "import torch\n",
        "import ctranslate2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract waveform and mel-spectrogram from audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio(file_path, sr=16000):\n",
        "    \"\"\"\n",
        "    Load audio file and convert it to the expected sample rate (16kHz).\n",
        "    \"\"\"\n",
        "    audio, sample_rate = librosa.load(file_path, sr=sr)\n",
        "    return audio, sample_rate\n",
        "\n",
        "def compute_mel_spectrogram(audio, sample_rate=16000):\n",
        "    \"\"\"\n",
        "    Compute the mel spectrogram from audio.\n",
        "    \"\"\"\n",
        "    # Using torchaudio for mel spectrogram conversion\n",
        "    waveform = torch.tensor(audio).unsqueeze(0)\n",
        "    mel_spec_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=80)\n",
        "    mel_spectrogram = mel_spec_transform(waveform).squeeze(0).numpy()\n",
        "    return mel_spectrogram\n",
        "\n",
        "# Load audio and compute mel spectrogram\n",
        "audio_file_path = '/content/1518.wav'\n",
        "text = \"he is currently completing a film titled helloween\"\n",
        "audio, sample_rate = load_audio(audio_file_path)\n",
        "mel_spectrogram = compute_mel_spectrogram(audio, sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Whisper model to Ctranslate2 Whisper "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1mdaHZhJH_c"
      },
      "source": [
        "Whisper model and processor comes in various versions including whisper-tiny, whisper-small, whisper-base, whisper-large-v1, whisper-large-v2, and whisper-large-v3. You can load Whisper model from Hugging Face using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "f0df680ee5484cfc947bdaaa16f39535",
            "8496accf7e6147d891d3ad0d4c2039cc",
            "d3fb72a5d58a41ddb69259fe3708cfc4",
            "7727738b371a43d7aed39e8bd449e69b",
            "dc64eaaaeace4668855c9b765185a513",
            "4b4a4d4352524264b4d9cc3d2d55a318",
            "689914e9e96f462ea48e44aea5ec86bd",
            "67ae7e9c45c349a4a18ea7d2094eca45",
            "6e7dd07ee8fe4abba49b1143c2ae3933",
            "974ea2a4fa4e4cd88907fa580f63a73e",
            "b0d3bcfb6e9b425dbeb1b04d176e2c46",
            "7605b1828e004fc08d5e9017f357cfd1",
            "ff90735f90614bb7aa3865875798242f",
            "8c15aa3b39d54c74b3598b7f485230e2",
            "132bcc97c8c249a99c43714358b3f6dc",
            "56988f1251104c468f697c1c503e015e",
            "6eabb05a58ca45f19e86b62059acad07",
            "a2d5d2bcb66c48dcb834706e4ac095ad",
            "bb01724524034c8abfe9eb949b47cb78",
            "7d7db6e8ac2f4426bd9c26f9c80817ae",
            "c8d3f46c83744d52bb0a1885453bcee0",
            "0d885d29b0044db789cc1f10d1c34d7a",
            "bf275399e3144234adb06ce3ce3cab0c",
            "8fe498fff8b24d4fb3f92f4bdaa428dd",
            "eb293fa6bae043e9a2e67035e0684ae1",
            "c6ddc856f0044ae993a537fc65a349bc",
            "931f4d8547b74e8d844de0fe18fdd0b1",
            "bc23dde5c5b748fcb9b227a6e42bd354",
            "a5c60dd914954e84b7293ce4689d0174",
            "7b60fb6b37c04fc1a9d40675ac2bc1b9",
            "cce3cf63e1e342e885ba249d392958b0",
            "b8812b76411a4eefa73e6b4845135085",
            "7f23f280e7384b2198efec08c9a56bd5",
            "1baf59292cd04649b299f5abf15e30f1",
            "d05904542e5d4179a8768763718bb16d",
            "2b7315d0c54c4d868cfddee1666e67f6",
            "091cca0b502549b4884519af2be7aa9d",
            "7cf08fdc549348a7bfe5d8bd282e3b4d",
            "d98c5ffa08e94b959bdcc26a2ab21166",
            "8ac8099101fb49899cb7edbfe7eaae85",
            "b69eeef38e7b4a3e85998e7fd530a659",
            "aa3380107d914fd6a99996813b4058d3",
            "6cdbe4832aa245319f094fa442267f52",
            "c34d27ea99c746409103fde501550a63",
            "77361e68ca1547e7a5626979c2523880",
            "585f8213df0b4385ab161cad27ca51e3",
            "80bc715520bb4bc382f668d43888049a",
            "7afecf8eef30445fa7fa79340b66ce2a",
            "5d3039a50b204e2b9ada34abdbcdb821",
            "473145318f9b49f7ac85108df482d628",
            "df7955a92f354bbd82fb835c59955c3b",
            "6e9d2a9878f547d995405c157133263a",
            "5fcafb7c4e1749eea5e4c1f313dd31fb",
            "5e28e9f7052342d6ab0c3ea77ec935a6",
            "479cb7196e8d4f22971a47e92d0e85a8",
            "85ff23e4ea174f229250f8933b397d98",
            "bcd8b661cf5f4472a0e1c05390461d5d",
            "a2d729557a174d9c8c83ee25d0699675",
            "21480f0600b64b869ba30e9c6a13f7ef",
            "53ad79a89b734951a3c06ebe835c48d8",
            "0e7c3edd05d346cc9f0d1b04f3b38ed1",
            "c0a02d6dd1e04085afab3e4b16c1c80e",
            "b4a2011d4d834896acb2e554e0427b41",
            "c9fa9b7654984e65906954daf8c97552",
            "1106ad50794846f58e1e59b41daca63c",
            "47753494ca87494090536c619ebcd90b",
            "8ac31de203b2469c8ef647ea76344a8b",
            "8fe5e54ba72e415f93e2bca90d4e6304",
            "19b7022ad70341cd86720ea2d5af6f42",
            "3c4006bb33454e28aa342e497240c574",
            "3ad3d07f653a4ad7a54ea733abe312d0",
            "a4dd52b1bd4540ad99f792a150f573fc",
            "8f7914cb03c542f193848457f25c7f2e",
            "9ccfacac5470412d9bf46e87939d05a8",
            "15df4cde8ceb45bc9f939718b6d4f9df",
            "4a923b50324642f5bb231cbf64fb5c02",
            "23b7056b1cd0418dae0b99874856e6ea",
            "9858c744c4da49cb90045972cdbabdf7",
            "c143b73537b148c48f5fbdf94ed45cc0",
            "5aa4630372a545bdaa8aa13adf8dded9",
            "3f13467489184532bb376c16a0def59a",
            "12a38487bde94716bf528c319fed2d5e",
            "304b81f81733462695a4c8cfb0355d6c",
            "eba608eb6de54a21a8c7a0cec51c0ab3",
            "2847dbd0ec0d49dcb0964a4d97e87a80",
            "545e2e50c28644549b176296dbee87aa",
            "22dec3634ca14a73b1045fe673bdd37a",
            "c4a74d4c7932499b988dd16d9265897f"
          ]
        },
        "id": "pbIvrGqrI9bg",
        "outputId": "ba5c7ba4-8361-4905-a945-823d95ff8971"
      },
      "outputs": [],
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
        "tokenizer = processor.tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe4jB4KD7Ftl"
      },
      "source": [
        "CTranslate2 provide command to converts the Whisper model to the CTranslate2 format, saves it in the whisper-base directory, copies the specified configuration files, applies float16 quantization, and overwrites any existing files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsHQbiXypkqY",
        "outputId": "4aa55ce2-f81f-4685-aaf8-a904e0e695b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.json: 100% 1.98k/1.98k [00:00<00:00, 14.1MB/s]\n",
            "model.safetensors: 100% 290M/290M [00:03<00:00, 88.8MB/s]\n",
            "generation_config.json: 100% 3.81k/3.81k [00:00<00:00, 23.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#The original model was converted with the following command:\n",
        "!ct2-transformers-converter --model openai/whisper-base --output_dir whisper-base \\\n",
        "    --copy_files tokenizer.json preprocessor_config.json --quantization float16 --force"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTranslate2 Whisper Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipxVKSnYM-ey"
      },
      "source": [
        "Load the Ctranslate2 Whisper model using the code below and set it up to run on the CPU. Alternatively, it is possible to use a GPU by setting the device variable to \"cuda\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyZQUo6IqXwy"
      },
      "outputs": [],
      "source": [
        "translator = ctranslate2.models.Whisper(\"/content/whisper-base\", device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60G6CZMIZFrJ"
      },
      "source": [
        "CTranslate2 methods use input features encoded as a StorageView via the ctranslate2.models.Whisper.encode() function. The input can be a mel spectrogram with shape [batch_size, n_mels, chunk_length], which, after encoding, will have the shape [batch_size, chunk_length // 2, d_model]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQBjZ9pYrV-"
      },
      "outputs": [],
      "source": [
        "# Prepare the input for Whisper model\n",
        "mel_spectrogram = np.expand_dims(mel_spectrogram, axis=0)  # Add batch dimension\n",
        "num_frames = mel_spectrogram.shape[2]  # Number of non-padding frames\n",
        "\n",
        "# Ensure the array has contiguous memory\n",
        "mel_spectrogram = np.ascontiguousarray(mel_spectrogram) # Use np.ascontiguousarray\n",
        "\n",
        "# Encode the audio features\n",
        "# Convert the NumPy array to a ctranslate2 StorageView\n",
        "encoded_features = translator.encode(ctranslate2.StorageView.from_array(mel_spectrogram)) # Use from_array method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmUKIYvoVpkJ"
      },
      "source": [
        "**Methods of Ctranslate2 for the Whisper Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXczDtFeKpj"
      },
      "source": [
        "**1. Align**\n",
        "\n",
        "Computes the alignment between the text tokens and the audio. This method is used to match parts of the text with corresponding segments of the audio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkGf8rtAtWtN",
        "outputId": "f71c2c03-f42b-4659-d1ec-415415b6536f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WhisperAlignmentResult(alignments=[(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (5, 20), (5, 21), (5, 22), (5, 23), (5, 24), (5, 25), (5, 26), (5, 27), (5, 28), (5, 29), (5, 30), (5, 31), (5, 32), (5, 33), (5, 34), (5, 35), (5, 36), (5, 37), (5, 38), (5, 39), (5, 40), (5, 41), (5, 42), (5, 43), (5, 44), (5, 45), (5, 46), (5, 47), (5, 48), (5, 49), (5, 50), (5, 51), (5, 52), (5, 53), (5, 54), (5, 55), (5, 56), (5, 57), (5, 58), (5, 59), (5, 60), (5, 61), (5, 62), (5, 63), (5, 64), (5, 65), (5, 66), (5, 67), (5, 68), (5, 69), (5, 70), (5, 71), (5, 72), (5, 73), (5, 74), (5, 75), (5, 76), (5, 77), (5, 78), (5, 79), (5, 80), (5, 81), (5, 82), (5, 83), (5, 84), (5, 85), (5, 86), (5, 87), (5, 88), (5, 89), (5, 90), (5, 91), (5, 92), (5, 93), (5, 94), (5, 95), (5, 96), (5, 97), (5, 98), (5, 99), (5, 100), (5, 101), (5, 102), (5, 103), (5, 104), (5, 105), (5, 106), (5, 107), (5, 108), (5, 109), (5, 110), (5, 111), (5, 112), (5, 113), (5, 114), (5, 115), (5, 116), (5, 117), (5, 118), (5, 119), (5, 120), (5, 121), (5, 122), (5, 123), (5, 124), (5, 125), (5, 126), (5, 127), (5, 128), (5, 129), (5, 130), (5, 131), (5, 132), (5, 133), (5, 134), (5, 135), (5, 136), (5, 137), (5, 138), (5, 139), (5, 140), (5, 141), (5, 142), (5, 143), (5, 144), (5, 145), (5, 146), (5, 147), (5, 148), (5, 149), (5, 150), (5, 151), (5, 152), (5, 153), (5, 154), (5, 155), (5, 156), (5, 157), (5, 158), (5, 159), (5, 160), (5, 161), (5, 162), (5, 163), (5, 164), (5, 165), (5, 166), (5, 167), (5, 168), (5, 169), (5, 170), (5, 171), (5, 172), (5, 173), (5, 174), (5, 175), (5, 176), (5, 177), (5, 178), (5, 179), (5, 180), (5, 181), (5, 182), (5, 183), (5, 184), (5, 185), (5, 186), (5, 187), (5, 188), (5, 189), (5, 190), (5, 191), (5, 192), (5, 193), (5, 194), (5, 195), (5, 196), (5, 197), (5, 198), (5, 199), (5, 200), (5, 201), (5, 202), (6, 202), (7, 202), (8, 202), (9, 202), (10, 202), (11, 202), (12, 202), (13, 202)], text_token_probs=[0.0, 0.0, 9.31674730964005e-05, 0.00015034245734568685, 9.820470586419106e-05, 1.2290715858398471e-05, 0.0016894906293600798, 0.00024034391390159726, 9.970764949684963e-06, 0.0027446651365607977, 2.384531626375974e-06, 6.964781732676784e-06, 0.0])]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the text\n",
        "text_tokens = tokenizer(text, return_tensors=\"pt\").input_ids.tolist()\n",
        "start_sequence = [tokenizer.pad_token_id]  # Define start-of-sequence token\n",
        "\n",
        "# Perform alignment\n",
        "alignment_result = translator.align(\n",
        "    features=encoded_features,\n",
        "    start_sequence=start_sequence,\n",
        "    text_tokens=text_tokens,\n",
        "    num_frames=num_frames\n",
        ")\n",
        "\n",
        "print(alignment_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqiykaLUrR0"
      },
      "source": [
        "In addition to the input audio features, we also need to provide other input parameters for this method, including:\n",
        "\n",
        "- *start_sequence* is the initial set of tokens or starting point for the\n",
        "alignment process.\n",
        "- *text_tokens* are the tokens of the text that the audio features should be aligned with.\n",
        "- *num_frames* is the number of non-padding frames in the audio features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnMo4qzJhadb"
      },
      "source": [
        "Example Result\n",
        "\n",
        "```python\n",
        "[WhisperAlignmentResult(\n",
        "    alignments=[(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (5, 1), (5, 2), (5, 3),...],\n",
        "    text_token_probs=[0.0, 0.0, 9.31674730964005e-05, 0.00015034245734568685, 9.820470586419106e-05, 1.2290715858398471e-05,...]\n",
        ")]\n",
        "```\n",
        "\n",
        "Here’s a simplified breakdown:\n",
        "\n",
        "- Alignments: A list of tuples where each tuple represents a mapping between the audio frames and text tokens. For instance, the tuple (5, 0) indicates that the audio frame 5 corresponds to text token 0.\n",
        "- Text Token Probabilities: A list of probabilities for each text token, indicating the confidence level for each token being represented in the audio. For example, a probability of 0.00015034245734568685 suggests a certain level of confidence for the corresponding text token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OczswtpwmaS"
      },
      "source": [
        "**2. Detect language**\n",
        "\n",
        "Detects the probability of each language present in the audio input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXa57mwtwxV0",
        "outputId": "8e7afdf4-efd1-4d6e-b732-4d0019878bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('<|en|>', 0.4817270040512085), ('<|zh|>', 0.13297148048877716), ('<|ur|>', 0.05135079845786095), ('<|ko|>', 0.0501541793346405), ('<|hi|>', 0.04444431513547897), ('<|jw|>', 0.03632590174674988), ('<|nn|>', 0.025384925305843353), ('<|th|>', 0.021732434630393982), ('<|ar|>', 0.017658809199929237), ('<|fi|>', 0.017540380358695984), ('<|tl|>', 0.013759175315499306), ('<|mi|>', 0.01273771096020937), ('<|es|>', 0.010259411297738552), ('<|haw|>', 0.010132383555173874), ('<|id|>', 0.00776319857686758), ('<|pl|>', 0.006979329977184534), ('<|cy|>', 0.006541122682392597), ('<|ja|>', 0.005686766933649778), ('<|km|>', 0.004785149823874235), ('<|la|>', 0.004033952485769987), ('<|br|>', 0.0025333447847515345), ('<|ca|>', 0.0022445733193308115), ('<|hu|>', 0.002153419889509678), ('<|el|>', 0.0021306227426975965), ('<|vi|>', 0.002113082678988576), ('<|fa|>', 0.0020975384395569563), ('<|ms|>', 0.002069794572889805), ('<|sn|>', 0.001886482466943562), ('<|bn|>', 0.0014842855744063854), ('<|si|>', 0.0014536735834553838), ('<|lv|>', 0.001148792915046215), ('<|de|>', 0.0010771839879453182), ('<|sw|>', 0.0010387252550572157), ('<|te|>', 0.001036842935718596), ('<|ml|>', 0.0009682944510132074), ('<|sa|>', 0.0009516945574432611), ('<|ps|>', 0.0007454607984982431), ('<|fo|>', 0.0007327467319555581), ('<|uk|>', 0.0007287729531526566), ('<|sk|>', 0.0006650783470831811), ('<|he|>', 0.0006569514516741037), ('<|lt|>', 0.0005957154207862914), ('<|af|>', 0.0005183756584301591), ('<|da|>', 0.0004274171660654247), ('<|ne|>', 0.0004247758479323238), ('<|ro|>', 0.0003985904040746391), ('<|ru|>', 0.0003765258297789842), ('<|kn|>', 0.00036417855881154537), ('<|yi|>', 0.00033094637910835445), ('<|gl|>', 0.00032377371098846197), ('<|be|>', 0.00029527200968004763), ('<|hr|>', 0.00029441830702126026), ('<|mr|>', 0.00028614813345484436), ('<|ta|>', 0.00023951749608386308), ('<|hy|>', 0.0002238876768387854), ('<|yo|>', 0.000211001664865762), ('<|sd|>', 0.00020885271078441292), ('<|it|>', 0.0002052370400633663), ('<|sr|>', 0.00020412285812199116), ('<|cs|>', 0.00017662225582171232), ('<|sl|>', 0.00017597463738638908), ('<|no|>', 0.00016452489944640547), ('<|et|>', 0.00012506228813435882), ('<|sv|>', 0.0001239492412423715), ('<|tr|>', 0.0001238370023202151), ('<|bs|>', 0.00010499050404177979), ('<|my|>', 9.946199133992195e-05), ('<|fr|>', 9.862888691714033e-05), ('<|oc|>', 9.623541700420901e-05), ('<|lo|>', 9.406441677128896e-05), ('<|bo|>', 8.93524193088524e-05), ('<|pa|>', 7.725127215962857e-05), ('<|mt|>', 6.99326119502075e-05), ('<|eu|>', 6.74088005325757e-05), ('<|so|>', 6.217326154001057e-05), ('<|mn|>', 5.653678090311587e-05), ('<|az|>', 5.250694084679708e-05), ('<|tg|>', 4.7888606786727905e-05), ('<|sq|>', 4.351044481154531e-05), ('<|kk|>', 3.465179179329425e-05), ('<|lb|>', 3.221337829018012e-05), ('<|nl|>', 2.9160481062717736e-05), ('<|ka|>', 2.4354738343390636e-05), ('<|as|>', 2.024099012487568e-05), ('<|is|>', 1.616759254829958e-05), ('<|pt|>', 1.384951792715583e-05), ('<|mk|>', 1.352515937469434e-05), ('<|ht|>', 1.1111686035292223e-05), ('<|bg|>', 9.84241887636017e-06), ('<|ha|>', 4.776999048772268e-06), ('<|gu|>', 3.898653631040361e-06), ('<|uz|>', 3.5799639590550214e-06), ('<|am|>', 3.536286158123403e-06), ('<|su|>', 3.2621071568428306e-06), ('<|tt|>', 2.6103850814251928e-06), ('<|ln|>', 2.5049491796380607e-06), ('<|tk|>', 2.4681532977410825e-06), ('<|ba|>', 2.3435675302607706e-06), ('<|mg|>', 1.5548347391813877e-06)]]\n"
          ]
        }
      ],
      "source": [
        "detected_language = translator.detect_language(encoded_features)\n",
        "print(detected_language)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha8iCgM9kr6-"
      },
      "source": [
        "Example result:\n",
        "```python\n",
        "[[('<|en|>', 0.4817270040512085), ('<|zh|>', 0.13297148048877716), ('<|ur|>', 0.05135079845786095), ('<|ko|>', 0.0501541793346405), ('<|hi|>', 0.04444431513547897), ('<|jw|>', 0.03632590174674988), ('<|nn|>', 0.025384925305843353), ('<|th|>', 0.021732434630393982), ('<|ar|>', 0.017658809199929237), ('<|fi|>', 0.017540380358695984), ('<|tl|>', 0.013759175315499306), ('<|mi|>', 0.01273771096020937), ('<|es|>', 0.010259411297738552)]]\n",
        "```\n",
        "\n",
        "The output from the detected_language method provides a list of language codes with their associated probabilities. Each entry in the list consists of a language code and a probability score, representing the likelihood of that language being present in the provided audio features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93wcgOsP33k8"
      },
      "source": [
        "**3. Generate**\n",
        "\n",
        "The generate method creates text from audio features and prompts. It processes the data using different decoding strategies and parameters, allowing customization of output length, token penalties, and additional information such as scores and probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGwkuNMu32Rw",
        "outputId": "d5f83687-6137-4bc0-af4b-dbe1f391d4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WhisperGenerationResult(sequences=[['<|0.00|>', 'ĠI', 'ĠI', 'ĠI', 'ĠI', 'ĠI']], sequences_ids=[[50364, 286, 286, 286, 286, 286]], scores=[-2.9740664958953857], no_speech_prob=0.004551995545625687)]\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Union, Optional\n",
        "\n",
        "generate_params = {\n",
        "    \"beam_size\": 5,\n",
        "    \"patience\": 5,  # Increased for longer sequences\n",
        "    \"length_penalty\": 1.0,\n",
        "    \"repetition_penalty\": 1.0,  # Reduced to allow more repetition if needed\n",
        "    \"no_repeat_ngram_size\": 0,  # Disabled to allow any sequence\n",
        "    \"max_length\": 448,\n",
        "    \"return_scores\": True,\n",
        "    \"return_no_speech_prob\": True\n",
        "}\n",
        "\n",
        "prompts = tokenizer.convert_tokens_to_ids(\n",
        "        [\n",
        "            \"<|startoftranscript|>\",\n",
        "            \"<|en|>\",\n",
        "            \"<|transcribe|>\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Generate text from audio\n",
        "generation_results = translator.generate(encoded_features, [prompts], **generate_params) # Pass features and prompts as arguments\n",
        "print(generation_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB7OYAyrmXuR"
      },
      "source": [
        "Since the result is returned in the form of tokens, the decode function is used to convert the token sequence into standard text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfK8AGoWlhI1",
        "outputId": "914f9b0c-25a2-4c76-c7c0-52c9d6a94b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I I I I I\n"
          ]
        }
      ],
      "source": [
        "# Token IDs from the result\n",
        "token_ids = generation_results[0].sequences_ids[0]\n",
        "\n",
        "# Decode the token IDs to text\n",
        "decoded_text = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
        "\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRrKfelW3KYY"
      },
      "source": [
        "# **Faster Whisper transcription with CTranslate2**\n",
        "\n",
        "In the previous section, we explored CTranslate2 and the functionality of its various methods. In this section, we will introduce a specific implementation of the Whisper model, leveraging the operational principles of CTranslate2, known as Faster-Whisper.\n",
        "\n",
        "Faster-Whisper represents a reimplementation of OpenAI's Whisper model utilizing CTranslate2, a high-performance inference engine designed for Transformer models. This implementation achieves up to a fourfold increase in inference speed compared to openai/whisper, while maintaining equivalent accuracy and requiring less memory. Furthermore, its efficiency can be enhanced through 8-bit quantization on both CPU and GPU, optimizing performance further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H0nxsI2gqiy"
      },
      "source": [
        "Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SbgHhOMJ24Ot",
        "outputId": "614fd3b7-457e-4016-967f-133360bc3a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.24.7)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.19.2)\n",
            "Requirement already satisfied: pyannote-audio>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: torch>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (2.4.1)\n",
            "Requirement already satisfied: torchaudio>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (2.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.66.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (74.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.28.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.2)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (0.8.0)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (2.6.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (13.8.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (3.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (0.12.1)\n",
            "Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (1.0.1)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (0.11.1)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-audio>=3.1.1->faster-whisper) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.1->faster-whisper) (12.6.68)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (0.11.7)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.1.1->faster-whisper) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.1.1->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.1.1->faster-whisper) (1.14.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (0.12.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (1.5.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (3.9.2)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (4.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.1.1->faster-whisper) (1.17.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper) (0.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.10.2.post1)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (1.2.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.1->faster-whisper) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.8.30)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.1.1->faster-whisper) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (3.10.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (2.9.0.post0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (2.0.34)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (3.5.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper) (0.18.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (1.3.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper) (4.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper) (1.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper) (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install faster-whisper -U\n",
        "!pip install transformers -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "igzPGOt2ahyY",
        "outputId": "f80985dc-8906-4f6e-9d49-41215d1a54f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "  Downloading https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m38.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached ctranslate2-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting huggingface_hub>=0.13 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers<1,>=0.13 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pyannote-audio>=3.1.1 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torch>=2.1.1 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchaudio>=2.1.2 (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading torchaudio-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting tqdm (from faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting setuptools (from ctranslate2<5,>=4.0->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached setuptools-74.1.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting numpy (from ctranslate2<5,>=4.0->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m430.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml<7,>=5.3 (from ctranslate2<5,>=4.0->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting filelock (from huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.9 (from huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting requests (from huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting sympy (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting einops>=0.6.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting lightning>=2.0.1 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting omegaconf<3.0,>=2.1 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pyannote.database-5.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rich>=12.0.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting semver>=3.0.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting soundfile>=0.12.1 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading speechbrain-1.0.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading torch_audiomentations-0.11.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting networkx (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sortedcontainers>=2.0.4 (from pyannote.core>=5.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting scipy>=1.1 (from pyannote.core>=5.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=0.19 (from pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting typer>=0.12.1 (from pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting scikit-learn>=0.17.1 (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tabulate>=0.7.7 (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting matplotlib>=2.0.0 (from pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting numpy (from ctranslate2<5,>=4.0->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting joblib (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting sentencepiece (from speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting librosa>=0.6.0 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting decorator>=4.3.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting numba>=0.51.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pooch>=1.1 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting lazy-loader>=0.1 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sqlalchemy>=1.3.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached SQLAlchemy-2.0.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting click>=8.0.0 (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached platformdirs-4.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.1.1->faster-whisper@ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Using cached greenlet-3.1.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Using cached ctranslate2-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.2 MB)\n",
            "Downloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m489.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m645.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m382.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.4.1-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
            "Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Using cached filelock-3.16.0-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "Downloading speechbrain-1.0.1-py3-none-any.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.2/807.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached setuptools-74.1.2-py3-none-any.whl (1.3 MB)\n",
            "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached idna-3.8-py3-none-any.whl (66 kB)\n",
            "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
            "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
            "Using cached SQLAlchemy-2.0.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
            "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "Using cached greenlet-3.1.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (617 kB)\n",
            "Using cached llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "Using cached platformdirs-4.3.2-py3-none-any.whl (18 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: faster-whisper, antlr4-python3-runtime, docopt, julius\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-1.0.3-py3-none-any.whl size=18418815 sha256=575e533db3d9febe86ad5cd55b7140b46d32146a7ca4fc549aecc06b21a826f8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bgcgv5kk/wheels/17/de/98/43933b6b40f936490d47ab88af0466d2680d7539ca36edd0d5\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=55571eb558fc8d439dde053b1d3d7b44a6a911ae1d9e6e647f917b8a4b27f32f\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=560c7e7bd4f931c33c136c29d05c619be51ad1dc224bd66bec595dd0bf462730\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=2bddc7272145be5fbfedd138eaabd935a947d44e4d5ef046d3e2d367b40871cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "Successfully built faster-whisper antlr4-python3-runtime docopt julius\n",
            "Installing collected packages: sortedcontainers, sentencepiece, pytz, primePy, mpmath, flatbuffers, docopt, antlr4-python3-runtime, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tabulate, sympy, six, shellingham, setuptools, semver, ruamel.yaml.clib, pyyaml, pyparsing, pygments, pycparser, protobuf, platformdirs, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, msgpack, mdurl, MarkupSafe, llvmlite, kiwisolver, joblib, idna, humanfriendly, greenlet, fsspec, frozenlist, fonttools, filelock, einops, decorator, cycler, colorlog, click, charset-normalizer, certifi, audioread, attrs, async-timeout, aiohappyeyeballs, triton, tensorboardX, sqlalchemy, soxr, scipy, ruamel.yaml, requests, python-dateutil, omegaconf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, multidict, markdown-it-py, Mako, lightning-utilities, lazy-loader, jinja2, ctranslate2, contourpy, coloredlogs, cffi, aiosignal, yarl, soundfile, scikit-learn, rich, pyannote.core, pooch, pandas, onnxruntime, nvidia-cusolver-cu12, matplotlib, hyperpyyaml, huggingface_hub, alembic, typer, torch, tokenizers, optuna, librosa, aiohttp, torchmetrics, torchaudio, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote-audio, faster-whisper\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.1\n",
            "    Uninstalling pytz-2024.1:\n",
            "      Successfully uninstalled pytz-2024.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2024.1\n",
            "    Uninstalling tzdata-2024.1:\n",
            "      Successfully uninstalled tzdata-2024.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.5.0\n",
            "    Uninstalling threadpoolctl-3.5.0:\n",
            "      Successfully uninstalled threadpoolctl-3.5.0\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.9.0\n",
            "    Uninstalling tabulate-0.9.0:\n",
            "      Successfully uninstalled tabulate-0.9.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.4\n",
            "    Uninstalling pyparsing-3.1.4:\n",
            "      Successfully uninstalled pyparsing-3.1.4\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.16.1\n",
            "    Uninstalling Pygments-2.16.1:\n",
            "      Successfully uninstalled Pygments-2.16.1\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.22\n",
            "    Uninstalling pycparser-2.22:\n",
            "      Successfully uninstalled pycparser-2.22\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.3.2\n",
            "    Uninstalling platformdirs-4.3.2:\n",
            "      Successfully uninstalled platformdirs-4.3.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.22.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.22.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.22.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.8\n",
            "    Uninstalling msgpack-1.0.8:\n",
            "      Successfully uninstalled msgpack-1.0.8\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.7\n",
            "    Uninstalling kiwisolver-1.4.7:\n",
            "      Successfully uninstalled kiwisolver-1.4.7\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.8\n",
            "    Uninstalling idna-3.8:\n",
            "      Successfully uninstalled idna-3.8\n",
            "  Attempting uninstall: humanfriendly\n",
            "    Found existing installation: humanfriendly 10.0\n",
            "    Uninstalling humanfriendly-10.0:\n",
            "      Successfully uninstalled humanfriendly-10.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.1.0\n",
            "    Uninstalling greenlet-3.1.0:\n",
            "      Successfully uninstalled greenlet-3.1.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.4.1\n",
            "    Uninstalling frozenlist-1.4.1:\n",
            "      Successfully uninstalled frozenlist-1.4.1\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.53.1\n",
            "    Uninstalling fonttools-4.53.1:\n",
            "      Successfully uninstalled fonttools-4.53.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.0\n",
            "    Uninstalling filelock-3.16.0:\n",
            "      Successfully uninstalled filelock-3.16.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: audioread\n",
            "    Found existing installation: audioread 3.0.1\n",
            "    Uninstalling audioread-3.0.1:\n",
            "      Successfully uninstalled audioread-3.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 4.0.3\n",
            "    Uninstalling async-timeout-4.0.3:\n",
            "      Successfully uninstalled async-timeout-4.0.3\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.4.0\n",
            "    Uninstalling aiohappyeyeballs-2.4.0:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.4.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.34\n",
            "    Uninstalling SQLAlchemy-2.0.34:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.34\n",
            "  Attempting uninstall: soxr\n",
            "    Found existing installation: soxr 0.5.0.post1\n",
            "    Uninstalling soxr-0.5.0.post1:\n",
            "      Successfully uninstalled soxr-0.5.0.post1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.1.0\n",
            "    Uninstalling multidict-6.1.0:\n",
            "      Successfully uninstalled multidict-6.1.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: lazy-loader\n",
            "    Found existing installation: lazy_loader 0.4\n",
            "    Uninstalling lazy_loader-0.4:\n",
            "      Successfully uninstalled lazy_loader-0.4\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: ctranslate2\n",
            "    Found existing installation: ctranslate2 4.4.0\n",
            "    Uninstalling ctranslate2-4.4.0:\n",
            "      Successfully uninstalled ctranslate2-4.4.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.0\n",
            "    Uninstalling contourpy-1.3.0:\n",
            "      Successfully uninstalled contourpy-1.3.0\n",
            "  Attempting uninstall: coloredlogs\n",
            "    Found existing installation: coloredlogs 15.0.1\n",
            "    Uninstalling coloredlogs-15.0.1:\n",
            "      Successfully uninstalled coloredlogs-15.0.1\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.17.1\n",
            "    Uninstalling cffi-1.17.1:\n",
            "      Successfully uninstalled cffi-1.17.1\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.3.1\n",
            "    Uninstalling aiosignal-1.3.1:\n",
            "      Successfully uninstalled aiosignal-1.3.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.11.1\n",
            "    Uninstalling yarl-1.11.1:\n",
            "      Successfully uninstalled yarl-1.11.1\n",
            "  Attempting uninstall: soundfile\n",
            "    Found existing installation: soundfile 0.12.1\n",
            "    Uninstalling soundfile-0.12.1:\n",
            "      Successfully uninstalled soundfile-0.12.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.8.1\n",
            "    Uninstalling rich-13.8.1:\n",
            "      Successfully uninstalled rich-13.8.1\n",
            "  Attempting uninstall: pooch\n",
            "    Found existing installation: pooch 1.8.2\n",
            "    Uninstalling pooch-1.8.2:\n",
            "      Successfully uninstalled pooch-1.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.19.2\n",
            "    Uninstalling onnxruntime-1.19.2:\n",
            "      Successfully uninstalled onnxruntime-1.19.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.6\n",
            "    Uninstalling huggingface-hub-0.24.6:\n",
            "      Successfully uninstalled huggingface-hub-0.24.6\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.5\n",
            "    Uninstalling typer-0.12.5:\n",
            "      Successfully uninstalled typer-0.12.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.10.5\n",
            "    Uninstalling aiohttp-3.10.5:\n",
            "      Successfully uninstalled aiohttp-3.10.5\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.4.0+cu121\n",
            "    Uninstalling torchaudio-2.4.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.4.0+cu121\n",
            "  Attempting uninstall: faster-whisper\n",
            "    Found existing installation: faster-whisper 1.0.3\n",
            "    Uninstalling faster-whisper-1.0.3:\n",
            "      Successfully uninstalled faster-whisper-1.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.28.1 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.9.0 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.1 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.1 which is incompatible.\n",
            "torchvision 0.19.0+cu121 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\n",
            "transformers 4.44.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 MarkupSafe-2.1.5 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 alembic-1.13.2 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 async-timeout-4.0.3 attrs-24.2.0 audioread-3.0.1 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.3.2 click-8.1.7 coloredlogs-15.0.1 colorlog-6.8.2 contourpy-1.3.0 ctranslate2-4.4.0 cycler-0.12.1 decorator-5.1.1 docopt-0.6.2 einops-0.8.0 faster-whisper-1.0.3 filelock-3.16.0 flatbuffers-24.3.25 fonttools-4.53.1 frozenlist-1.4.1 fsspec-2024.9.0 greenlet-3.1.0 huggingface_hub-0.24.7 humanfriendly-10.0 hyperpyyaml-1.2.2 idna-3.8 jinja2-3.1.4 joblib-1.4.2 julius-0.2.7 kiwisolver-1.4.7 lazy-loader-0.4 librosa-0.10.2.post1 lightning-2.4.0 lightning-utilities-0.11.7 llvmlite-0.43.0 markdown-it-py-3.0.0 matplotlib-3.9.2 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 networkx-3.3 numba-0.60.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnxruntime-1.19.2 optuna-4.0.0 packaging-24.1 pandas-2.2.2 pillow-10.4.0 platformdirs-4.3.2 pooch-1.8.2 primePy-1.3 protobuf-5.28.1 pyannote-audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pycparser-2.22 pygments-2.18.0 pyparsing-3.1.4 python-dateutil-2.9.0.post0 pytorch-lightning-2.4.0 pytorch-metric-learning-2.6.0 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 rich-13.8.1 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 scikit-learn-1.5.2 scipy-1.14.1 semver-3.0.2 sentencepiece-0.2.0 setuptools-74.1.2 shellingham-1.5.4 six-1.16.0 sortedcontainers-2.4.0 soundfile-0.12.1 soxr-0.5.0.post1 speechbrain-1.0.1 sqlalchemy-2.0.34 sympy-1.13.2 tabulate-0.9.0 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 tokenizers-0.20.0 torch-2.4.1 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 torchaudio-2.4.1 torchmetrics-1.4.1 tqdm-4.66.5 triton-3.0.0 typer-0.12.5 typing-extensions-4.12.2 tzdata-2024.1 urllib3-2.2.3 yarl-1.11.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "dd466e3fe6a84e2098eb7f999a32c887",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "cffi",
                  "charset_normalizer",
                  "ctranslate2",
                  "cycler",
                  "dateutil",
                  "decorator",
                  "faster_whisper",
                  "huggingface_hub",
                  "kiwisolver",
                  "onnxruntime",
                  "pkg_resources",
                  "pydevd_plugins",
                  "requests",
                  "setuptools",
                  "six",
                  "torch",
                  "torchgen",
                  "tqdm",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Other installation methods\n",
        "!pip install --force-reinstall \"faster-whisper @ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-b5hz2-YoH"
      },
      "source": [
        "**Sequential Inference faster-whisper**\n",
        "\n",
        "First, we use the Sequential inference method for the Whisper model, where the input audio is segmented and processed sequentially. Each audio segment is transcribed one by one, ensuring the model handles the input step by step.\n",
        "\n",
        "Here’s a summary of how Sequential inference method handles the transcription:\n",
        "- Sequential Processing: this method segments the audio and processes each segment in sequence. This allows the model to generate text from each audio chunk while maintaining context from previous segments.\n",
        "- Language Detection & VAD: It can automatically detect the language if not specified and filter out non-speech segments using voice activity detection.\n",
        "- Final Output: this method returns a generator that yields transcribed segments and additional transcription details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SCb06Zv3oe3",
        "outputId": "1d6a8e70-8fed-462d-e6fa-f3abcfff5b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object restore_speech_timestamps at 0x794e11d14c10> TranscriptionInfo(language='en', language_probability=1, duration=5.064, duration_after_vad=4.408, all_language_probs=None, transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, log_prob_low_threshold=None, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=(1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50359, 50360, 50361, 50362), without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'“¿([{-', append_punctuations='\"\\'.。,，!！?？:：”)]}、', multilingual=False, output_language=None, max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=VadOptions(threshold=0.5, min_speech_duration_ms=250, max_speech_duration_s=inf, min_silence_duration_ms=2000, speech_pad_ms=400))\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "# Define the file path for the audio to be transcribed\n",
        "filepath = \"/content/1518.wav\"\n",
        "\n",
        "# Configuration parameters for transcription\n",
        "word_timestamps = False  # Do not include word-level timestamps\n",
        "vad_filter = True  # Apply Voice Activity Detection to remove non-speech segments\n",
        "temperature = 0.0  # Use deterministic transcription\n",
        "language = \"en\"  # Set language to English\n",
        "model_size = \"large-v3\"  # Use the \"large-v3\" model\n",
        "device, compute_type = \"cpu\", \"float32\"  # Set computation device and precision\n",
        "\n",
        "# Initialize the Whisper model\n",
        "model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "\n",
        "# Transcribe the audio file with the specified settings\n",
        "segments, transcription_info = model.transcribe(\n",
        "    filepath,\n",
        "    word_timestamps=word_timestamps,\n",
        "    vad_filter=vad_filter,\n",
        "    temperature=temperature,\n",
        "    language=language,\n",
        ")\n",
        "\n",
        "# Output the transcription results and metadata\n",
        "print(segments, transcription_info)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt9FfdUCQh1O"
      },
      "source": [
        "Output\n",
        "\n",
        "segments\n",
        "\n",
        "```python\n",
        "<generator object restore_speech_timestamps at 0x7ec0dd52edc0>\n",
        "```\n",
        "\n",
        "transcription_info\n",
        "\n",
        "```python\n",
        "TranscriptionInfo(language='en', language_probability=1, duration=5.064, duration_after_vad=4.408, all_language_probs=None, transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=[-1], without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'“¿([{-', append_punctuations='\"\\'.。,，!！?？:：”)]}、', max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=VadOptions(threshold=0.5, min_speech_duration_ms=250, max_speech_duration_s=inf, min_silence_duration_ms=2000, speech_pad_ms=400))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsIRTuot86Zn"
      },
      "source": [
        "Segments are transcription segments extracted from the audio file, each represented as an object. Each segment includes information about the audio portion it corresponds to, such as start time, end time, and transcribed text. By iterating through these segments, you can extract and process the entire transcription content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlkw37Cg85dh",
        "outputId": "4c4b7c3f-0974-4ce8-d53e-ce2f7035685b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'start': 0.66, 'end': 3.9, 'text': ' He is currently completing a film titled Halloween.'}\n"
          ]
        }
      ],
      "source": [
        "for segment in segments:\n",
        "    row = {\n",
        "        \"start\": segment.start,\n",
        "        \"end\": segment.end,\n",
        "        \"text\": segment.text,\n",
        "    }\n",
        "    if word_timestamps:\n",
        "        row[\"words\"] = [\n",
        "            {\"start\": word.start, \"end\": word.end, \"word\": word.word}\n",
        "            for word in segment.words\n",
        "        ]\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI2XEBMjX7PX"
      },
      "source": [
        "Additionally, to extracts word-level timestamps from an audio file, providing the start and end times for each word. This detailed information facilitates in-depth analysis and processing of the transcription data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSXqRcFdaHq0",
        "outputId": "49d7b113-95d5-4d79-b648-d062c8091ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00s -> 1.06s]  He\n",
            "[1.06s -> 1.18s]  is\n",
            "[1.18s -> 1.50s]  currently\n",
            "[1.50s -> 2.06s]  completing\n",
            "[2.06s -> 2.34s]  a\n",
            "[2.34s -> 2.54s]  film\n",
            "[2.54s -> 2.96s]  titled\n",
            "[2.96s -> 3.70s]  Halloween.\n"
          ]
        }
      ],
      "source": [
        "segments, _ = model.transcribe(\"/content/1518.wav\", word_timestamps=True)\n",
        "\n",
        "for segment in segments:\n",
        "    for word in segment.words:\n",
        "        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-J1a5MQ-gtf"
      },
      "source": [
        "**Batched inference faster-whisper**\n",
        "\n",
        "Parallel processing of audio chunks can significantly enhance inference performance compared to sequential processing methods, such as those used in sequential inference with Faster Whisper. This method involves:\n",
        "\n",
        "- Breaking the audio into semantically meaningful chunks.\n",
        "- Transcribing these chunks in parallel (as batches), utilizing a faster feature extraction process and VAD to skip non-speech portions.\n",
        "\n",
        "This approach results in considerably faster transcription, especially for long audio files, without sacrificing accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pFFtfQLu-Ja5",
        "outputId": "f9288f7b-75b4-40d9-a541-dc882dae2907"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.10/dist-packages/faster_whisper/assets/pyannote_vad_model.bin`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
            "[0.94s -> 4.43s]  He is currently completing a film titled Halloween.\n"
          ]
        }
      ],
      "source": [
        "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "\n",
        "# Define file path for the audio to be transcribed\n",
        "filename = \"/content/1518.wav\"\n",
        "\n",
        "# Configuration settings\n",
        "word_timestamps = False  # Disable word-level timestamps\n",
        "vad_filter = True  # Enable Voice Activity Detection to filter out non-speech segments\n",
        "temperature = 0.0  # Set temperature to 0.0 for deterministic transcription\n",
        "language = \"en\"  # Set language to English\n",
        "model_size = \"large-v3\"  # Use the \"large-v3\" Whisper model\n",
        "device, compute_type = \"cpu\", \"float32\"  # Set computation to use CPU and float32 precision\n",
        "\n",
        "# Initialize the Whisper model\n",
        "model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "\n",
        "# Wrap the model in a BatchedInferencePipeline for batch processing\n",
        "batched_model = BatchedInferencePipeline(model=model)\n",
        "\n",
        "# Perform transcription on the audio file using batch processing with batch_size of 16\n",
        "segments, info = batched_model.transcribe(filename, batch_size=16)\n",
        "\n",
        "for segment in segments:\n",
        "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDHKa04H-A7p"
      },
      "source": [
        "**Multi-segment language detection**\n",
        "\n",
        "This language detection method uses the detect_language_multi_segment method to analyze an audio file. This method segments the audio into multiple parts and determines the language based on highly-confident segments, aggregating these results to accurately identify the overall language. By leveraging a segmented approach, the method enhances reliability and accuracy, particularly in cases with varying audio quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "573GXI7j8_j3"
      },
      "outputs": [],
      "source": [
        "from faster_whisper import WhisperModel\n",
        "\n",
        "model = WhisperModel(\"medium\", device=\"cpu\", compute_type=\"float32\")\n",
        "language_info = model.detect_language_multi_segment(\"audio.mp3\")\n",
        "print(language_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqFPiClVbTTs"
      },
      "source": [
        "Finally, we will test all three inference methods, including the Whisper model from OpenAI, Faster Whisper Sequential, and Faster Whisper Batched, using the same audio sample. This will allow us to compare the speed and results of each method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5dPcdYobSR5",
        "outputId": "9c556fa4-0384-4e2a-81d6-f1927c8df2c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.10/dist-packages/faster_whisper/assets/pyannote_vad_model.bin`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "import whisper\n",
        "\n",
        "# Define the file path for the audio to be transcribed\n",
        "filepath = \"/content/1518.wav\"\n",
        "\n",
        "# Configuration parameters for transcription\n",
        "word_timestamps = False  # Do not include word-level timestamps\n",
        "vad_filter = True  # Apply Voice Activity Detection to remove non-speech segments\n",
        "temperature = 0.0  # Use deterministic transcription\n",
        "language = \"en\"  # Set language to English\n",
        "model_size = \"large-v3\"  # Use the \"large-v3\" model\n",
        "device, compute_type = \"cpu\", \"float32\"  # Set computation device and precision\n",
        "\n",
        "# Initialize the Whisper model\n",
        "model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "\n",
        "time1 = time.time()\n",
        "# Transcribe the audio file with the specified settings\n",
        "segments, transcription_info = model.transcribe(\n",
        "    filepath,\n",
        "    word_timestamps=word_timestamps,\n",
        "    vad_filter=vad_filter,\n",
        "    temperature=temperature,\n",
        "    language=language,\n",
        ")\n",
        "time2 = time.time()\n",
        "\n",
        "# Wrap the model in a BatchedInferencePipeline for batch processing\n",
        "batched_model = BatchedInferencePipeline(model=model)\n",
        "\n",
        "time3 = time.time()\n",
        "# Perform transcription on the audio file using batch processing with batch_size of 16\n",
        "segments, info = batched_model.transcribe(filepath, batch_size=16)\n",
        "time4 = time.time()\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "time5 = time.time()\n",
        "# Perform transcription\n",
        "result = model.transcribe(file_path, language=language)\n",
        "time6 = time.time()\n",
        "\n",
        "print(\"Time inference from Whisper model from OpenAI: \", time6 - time5)\n",
        "print(\"Time inference from Faster Whisper Sequential: \", time2 - time1)\n",
        "print(\"Time inference from Faster Whisper Batched: \", time4 - time3)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "091cca0b502549b4884519af2be7aa9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cdbe4832aa245319f094fa442267f52",
            "placeholder": "​",
            "style": "IPY_MODEL_c34d27ea99c746409103fde501550a63",
            "value": " 2.48M/2.48M [00:01&lt;00:00, 2.42MB/s]"
          }
        },
        "0d885d29b0044db789cc1f10d1c34d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7c3edd05d346cc9f0d1b04f3b38ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1106ad50794846f58e1e59b41daca63c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a38487bde94716bf528c319fed2d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132bcc97c8c249a99c43714358b3f6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d3f46c83744d52bb0a1885453bcee0",
            "placeholder": "​",
            "style": "IPY_MODEL_0d885d29b0044db789cc1f10d1c34d7a",
            "value": " 283k/283k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "15df4cde8ceb45bc9f939718b6d4f9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19b7022ad70341cd86720ea2d5af6f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ccfacac5470412d9bf46e87939d05a8",
            "max": 34604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15df4cde8ceb45bc9f939718b6d4f9df",
            "value": 34604
          }
        },
        "1baf59292cd04649b299f5abf15e30f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d05904542e5d4179a8768763718bb16d",
              "IPY_MODEL_2b7315d0c54c4d868cfddee1666e67f6",
              "IPY_MODEL_091cca0b502549b4884519af2be7aa9d"
            ],
            "layout": "IPY_MODEL_7cf08fdc549348a7bfe5d8bd282e3b4d"
          }
        },
        "21480f0600b64b869ba30e9c6a13f7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1106ad50794846f58e1e59b41daca63c",
            "placeholder": "​",
            "style": "IPY_MODEL_47753494ca87494090536c619ebcd90b",
            "value": " 52.7k/52.7k [00:00&lt;00:00, 4.47MB/s]"
          }
        },
        "22dec3634ca14a73b1045fe673bdd37a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b7056b1cd0418dae0b99874856e6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2847dbd0ec0d49dcb0964a4d97e87a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7315d0c54c4d868cfddee1666e67f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69eeef38e7b4a3e85998e7fd530a659",
            "max": 2480466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa3380107d914fd6a99996813b4058d3",
            "value": 2480466
          }
        },
        "304b81f81733462695a4c8cfb0355d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad3d07f653a4ad7a54ea733abe312d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4006bb33454e28aa342e497240c574": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a923b50324642f5bb231cbf64fb5c02",
            "placeholder": "​",
            "style": "IPY_MODEL_23b7056b1cd0418dae0b99874856e6ea",
            "value": " 34.6k/34.6k [00:00&lt;00:00, 2.47MB/s]"
          }
        },
        "3f13467489184532bb376c16a0def59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22dec3634ca14a73b1045fe673bdd37a",
            "placeholder": "​",
            "style": "IPY_MODEL_c4a74d4c7932499b988dd16d9265897f",
            "value": " 2.19k/2.19k [00:00&lt;00:00, 162kB/s]"
          }
        },
        "473145318f9b49f7ac85108df482d628": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47753494ca87494090536c619ebcd90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479cb7196e8d4f22971a47e92d0e85a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a923b50324642f5bb231cbf64fb5c02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b4a4d4352524264b4d9cc3d2d55a318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ad79a89b734951a3c06ebe835c48d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "545e2e50c28644549b176296dbee87aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56988f1251104c468f697c1c503e015e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585f8213df0b4385ab161cad27ca51e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473145318f9b49f7ac85108df482d628",
            "placeholder": "​",
            "style": "IPY_MODEL_df7955a92f354bbd82fb835c59955c3b",
            "value": "merges.txt: 100%"
          }
        },
        "5aa4630372a545bdaa8aa13adf8dded9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2847dbd0ec0d49dcb0964a4d97e87a80",
            "max": 2194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_545e2e50c28644549b176296dbee87aa",
            "value": 2194
          }
        },
        "5d3039a50b204e2b9ada34abdbcdb821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e28e9f7052342d6ab0c3ea77ec935a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fcafb7c4e1749eea5e4c1f313dd31fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ae7e9c45c349a4a18ea7d2094eca45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689914e9e96f462ea48e44aea5ec86bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cdbe4832aa245319f094fa442267f52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7dd07ee8fe4abba49b1143c2ae3933": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e9d2a9878f547d995405c157133263a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eabb05a58ca45f19e86b62059acad07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7605b1828e004fc08d5e9017f357cfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff90735f90614bb7aa3865875798242f",
              "IPY_MODEL_8c15aa3b39d54c74b3598b7f485230e2",
              "IPY_MODEL_132bcc97c8c249a99c43714358b3f6dc"
            ],
            "layout": "IPY_MODEL_56988f1251104c468f697c1c503e015e"
          }
        },
        "7727738b371a43d7aed39e8bd449e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_974ea2a4fa4e4cd88907fa580f63a73e",
            "placeholder": "​",
            "style": "IPY_MODEL_b0d3bcfb6e9b425dbeb1b04d176e2c46",
            "value": " 185k/185k [00:00&lt;00:00, 534kB/s]"
          }
        },
        "77361e68ca1547e7a5626979c2523880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_585f8213df0b4385ab161cad27ca51e3",
              "IPY_MODEL_80bc715520bb4bc382f668d43888049a",
              "IPY_MODEL_7afecf8eef30445fa7fa79340b66ce2a"
            ],
            "layout": "IPY_MODEL_5d3039a50b204e2b9ada34abdbcdb821"
          }
        },
        "7afecf8eef30445fa7fa79340b66ce2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e28e9f7052342d6ab0c3ea77ec935a6",
            "placeholder": "​",
            "style": "IPY_MODEL_479cb7196e8d4f22971a47e92d0e85a8",
            "value": " 494k/494k [00:00&lt;00:00, 967kB/s]"
          }
        },
        "7b60fb6b37c04fc1a9d40675ac2bc1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf08fdc549348a7bfe5d8bd282e3b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7db6e8ac2f4426bd9c26f9c80817ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f23f280e7384b2198efec08c9a56bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80bc715520bb4bc382f668d43888049a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9d2a9878f547d995405c157133263a",
            "max": 493869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fcafb7c4e1749eea5e4c1f313dd31fb",
            "value": 493869
          }
        },
        "8496accf7e6147d891d3ad0d4c2039cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4a4d4352524264b4d9cc3d2d55a318",
            "placeholder": "​",
            "style": "IPY_MODEL_689914e9e96f462ea48e44aea5ec86bd",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "85ff23e4ea174f229250f8933b397d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcd8b661cf5f4472a0e1c05390461d5d",
              "IPY_MODEL_a2d729557a174d9c8c83ee25d0699675",
              "IPY_MODEL_21480f0600b64b869ba30e9c6a13f7ef"
            ],
            "layout": "IPY_MODEL_53ad79a89b734951a3c06ebe835c48d8"
          }
        },
        "8ac31de203b2469c8ef647ea76344a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fe5e54ba72e415f93e2bca90d4e6304",
              "IPY_MODEL_19b7022ad70341cd86720ea2d5af6f42",
              "IPY_MODEL_3c4006bb33454e28aa342e497240c574"
            ],
            "layout": "IPY_MODEL_3ad3d07f653a4ad7a54ea733abe312d0"
          }
        },
        "8ac8099101fb49899cb7edbfe7eaae85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c15aa3b39d54c74b3598b7f485230e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb01724524034c8abfe9eb949b47cb78",
            "max": 282683,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7db6e8ac2f4426bd9c26f9c80817ae",
            "value": 282683
          }
        },
        "8f7914cb03c542f193848457f25c7f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe498fff8b24d4fb3f92f4bdaa428dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc23dde5c5b748fcb9b227a6e42bd354",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c60dd914954e84b7293ce4689d0174",
            "value": "vocab.json: 100%"
          }
        },
        "8fe5e54ba72e415f93e2bca90d4e6304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4dd52b1bd4540ad99f792a150f573fc",
            "placeholder": "​",
            "style": "IPY_MODEL_8f7914cb03c542f193848457f25c7f2e",
            "value": "added_tokens.json: 100%"
          }
        },
        "931f4d8547b74e8d844de0fe18fdd0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974ea2a4fa4e4cd88907fa580f63a73e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9858c744c4da49cb90045972cdbabdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c143b73537b148c48f5fbdf94ed45cc0",
              "IPY_MODEL_5aa4630372a545bdaa8aa13adf8dded9",
              "IPY_MODEL_3f13467489184532bb376c16a0def59a"
            ],
            "layout": "IPY_MODEL_12a38487bde94716bf528c319fed2d5e"
          }
        },
        "9ccfacac5470412d9bf46e87939d05a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d5d2bcb66c48dcb834706e4ac095ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2d729557a174d9c8c83ee25d0699675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a2011d4d834896acb2e554e0427b41",
            "max": 52666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9fa9b7654984e65906954daf8c97552",
            "value": 52666
          }
        },
        "a4dd52b1bd4540ad99f792a150f573fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c60dd914954e84b7293ce4689d0174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa3380107d914fd6a99996813b4058d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d3bcfb6e9b425dbeb1b04d176e2c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a2011d4d834896acb2e554e0427b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69eeef38e7b4a3e85998e7fd530a659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8812b76411a4eefa73e6b4845135085": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb01724524034c8abfe9eb949b47cb78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc23dde5c5b748fcb9b227a6e42bd354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd8b661cf5f4472a0e1c05390461d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7c3edd05d346cc9f0d1b04f3b38ed1",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a02d6dd1e04085afab3e4b16c1c80e",
            "value": "normalizer.json: 100%"
          }
        },
        "bf275399e3144234adb06ce3ce3cab0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fe498fff8b24d4fb3f92f4bdaa428dd",
              "IPY_MODEL_eb293fa6bae043e9a2e67035e0684ae1",
              "IPY_MODEL_c6ddc856f0044ae993a537fc65a349bc"
            ],
            "layout": "IPY_MODEL_931f4d8547b74e8d844de0fe18fdd0b1"
          }
        },
        "c0a02d6dd1e04085afab3e4b16c1c80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c143b73537b148c48f5fbdf94ed45cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_304b81f81733462695a4c8cfb0355d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_eba608eb6de54a21a8c7a0cec51c0ab3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c34d27ea99c746409103fde501550a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4a74d4c7932499b988dd16d9265897f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ddc856f0044ae993a537fc65a349bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8812b76411a4eefa73e6b4845135085",
            "placeholder": "​",
            "style": "IPY_MODEL_7f23f280e7384b2198efec08c9a56bd5",
            "value": " 836k/836k [00:00&lt;00:00, 1.61MB/s]"
          }
        },
        "c8d3f46c83744d52bb0a1885453bcee0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fa9b7654984e65906954daf8c97552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cce3cf63e1e342e885ba249d392958b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d05904542e5d4179a8768763718bb16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98c5ffa08e94b959bdcc26a2ab21166",
            "placeholder": "​",
            "style": "IPY_MODEL_8ac8099101fb49899cb7edbfe7eaae85",
            "value": "tokenizer.json: 100%"
          }
        },
        "d3fb72a5d58a41ddb69259fe3708cfc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ae7e9c45c349a4a18ea7d2094eca45",
            "max": 184990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e7dd07ee8fe4abba49b1143c2ae3933",
            "value": 184990
          }
        },
        "d98c5ffa08e94b959bdcc26a2ab21166": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc64eaaaeace4668855c9b765185a513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7955a92f354bbd82fb835c59955c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb293fa6bae043e9a2e67035e0684ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b60fb6b37c04fc1a9d40675ac2bc1b9",
            "max": 835550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cce3cf63e1e342e885ba249d392958b0",
            "value": 835550
          }
        },
        "eba608eb6de54a21a8c7a0cec51c0ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0df680ee5484cfc947bdaaa16f39535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8496accf7e6147d891d3ad0d4c2039cc",
              "IPY_MODEL_d3fb72a5d58a41ddb69259fe3708cfc4",
              "IPY_MODEL_7727738b371a43d7aed39e8bd449e69b"
            ],
            "layout": "IPY_MODEL_dc64eaaaeace4668855c9b765185a513"
          }
        },
        "ff90735f90614bb7aa3865875798242f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eabb05a58ca45f19e86b62059acad07",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d5d2bcb66c48dcb834706e4ac095ad",
            "value": "tokenizer_config.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
